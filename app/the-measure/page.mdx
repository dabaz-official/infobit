# 信息的度量

信息的度量涉及很多概念，例如概念空间、先验概率、后验概率、自信息、互信息等。

## 自信息

### 自信息量

事件 $x_i$ 发生概率 $p(x_i)$ 的对数的负值。

$I(x_i) = -\log p(x_i)$

默认以 $2$ 为底，可不写底数 $2$。单位为比特（$bit$）。

#### 性质

- 单调性：$p(x_1)>p(x_2)\rarr I(x_1)<I(x_2)$
- 确定性：$p(x)=1\rarr I(x)=0$
- 独立性：两个独立事件提供的总信息量，应等于它们各自的信息量之和

### 条件自信息量

该事件 $x_i$ 在另一事件 $y_j$ 发生的情况下发生的概率的底数的负值。

$I(x_i|y_j) = -\log p(x_i|y_j)$